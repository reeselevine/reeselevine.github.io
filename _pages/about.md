---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: us.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    Santa Cruz, CA

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am a sixth (and final) year PhD candidate and an [NDSEG Fellow](https://ndseg.org/) at UC Santa Cruz, where I work with [Tyler Sorensen](https://users.soe.ucsc.edu/~tsorensen/) and am generally affiliated with the [LSD Lab](https://lsd.ucsc.edu/). My research interests are in parallel and concurrent programming. My work has focused on GPU programming models, including designing and evaluating techniques to test the conformance of compilers and hardware to memory model specifications [[1](assets/pdf/mc_mutants.pdf), [2](assets/pdf/gpuharbor.pdf)], and testing and improving the safety properties of GPU programming languages in the face of data races [[3](assets/pdf/saferace.pdf)].

I am currently collaborating on projects related to GPU security and compiler correctness. I am also actively contributing to [llama.cpp](https://github.com/ggml-org/llama.cpp) in order to bring GPU-accelerated inference to the browser using WebGPU, opening up research opportunities in portable performance, efficient LLM quantization, and improving GPU programming models.

<div class="alert alert-primary" role="alert">
I am currently exploring full-time opportunities! I am interested in working on GPU (or other accelerator) programming languages and architecture, AI infrastructure (especially but not limited to *local* LLM inference), or other roles related to parallel and concurrent programming. Please reach out if you have an opening or want to learn more about my research.
</div>
